# Chapter5 기억장치

# 기억장치의 분류와 특성

기준이 몇 가지 있을 수 있는데
* 1) 액세스(기억장치로부터 읽는 동작)의 유형
    * 순차적 액세스 : 처음부터 순서대로 액세스 -> 특정 위치 가려면 그 전 위치 다 읽어야 함
        * 자기 테이프가 이런 방식 이용
    * 직접 액세스 : 특정 블록의 근처로 이동 후 순차 검색으로 최종 위치 도달
        * 자기 디스크, CD-ROM, DVD 등
    * 임의 액세스 : 기억장치 내의 모든 저장 장소들은 고유의 주소를 가지고 있음
        * 어떤 위치에 액세스하든 시간은 항상 일정
        * 반도체 기억장치들이 이런 방식 이용
    * 연관 액세스 : 각 기억장소에 키와 해당하는 데이터(비트)들이 함께 저장됨
        * 주소 대신 비트 패턴으로 키값과 대조
        * 키값 하나씩 비교하면 시간이 많이 걸리므로 키값들을 동시에 비교할 수 있는
        하드웨어 포함
        * 특수한 용도로만 사용
* 기억장치에서 중요한 것은 용량과 액세스 속도(액세스 속도는 다음 변수들에 의해 결정)
    * 액세스 시간 : 기억장치에 도착하는 시간 + 데이터가 저장되거나 읽혀지는 동작이 완료되는 
    순간까지의 시간
    * 기억장치 사이클 시간 : 액세스 시간과 다음 액세스를 시작하기 위해 필요한 동작에 걸리는 추가적인 시간
    * 데이터 전송률 : 기억장치로부터 초당 읽혀지거나 쓰여질 수 있는 비트 수
* 2) 물리적인 재료
    * 반도체 기억장치(휘발성 또는 비휘발성)
    * 자기 표면 기억장치(비휘발성)
    * 광 저장장치(비휘발성)
* 3) 데이터를 저장하는 성질
    * 휘발성 기억장치 : 시간이 지남에 따라 사라지거나, 전력 공급이 중단되면 소멸 
    * 비휘발성 기억장치 : 일단 저장된 정보는 그대로 유지, 유지를 위해 전력 공급도 필요 없음 

# 계층적 기억장치 시스템

컴퓨터 성능에 가장 중요한 영향을 미치는 자원은 CPU, CPU가 아무리 빨라도 기억장치가 느리면 
CPU가 액세스를 위해 계속 기다리게 되어 시스템이 성능이 저하될 수 밖에 없음
이것이 문제의 핵심이다.

CPU가 프로그램 코드나 데이터를 인출하고자 할 때 
CPU -> 주기억장치 -> (주기억장치에 없으면)보조저장장치
순으로 접근한다. 그런데 주기억장치의 용량이 적으면 보조저장장치까지 접근하는 빈도가 높아짐
문제는 보조저장장치에 접근하는데 걸리는 시간이 주기억장치에 접근하는 데 걸리는 시간의 10만배 정도 느림
그렇다면 주기억장치 용량 키우면 되는데 주기억장치는 비싸다. 일반적인 경우 무작정 키울 수 없음

그러므로 한 가지 기억장치에 의존하는 것보다 여러 계층적 기억장치 시스템을 구성하는 것
만약 주기억장치와 보조기억장치로 구성된 시스템에서 주기억장치에 데이터가 있으면 바로 액세스 가능
없으면? 보조기억장치로 가야 함
하지만 그 과정에서 주기억장치에 저장해두면?
다음 번에는 바로 주기억장치에서 가져가면 된다.

CPU가 명령어와 데이터를 읽기 위해 기억장치에 액세스하는 위치를 조사하면 특정 영역에 집중되는 경향이 있음
ex) 루프, 서브루틴
이렇게 반복적으로 접근하는 영역의 데이터는 보조기억장치에서 읽어오면서 주기억장치에 저장해두면 이후 신속하게
접근 가능
-> "지역성의 원리"

계층 구조를 살펴보면

CPU 레지스터 : 가장 빠르고, 용량이 적으며, 비트당 가격이 가장 높은 기억장치

캐시 : 레지스터에 없을 때 주기억장치로부터 읽어오기 위해 상당히 긴 시간을 기다려야 하는데 그 중간에서 
버퍼 역할을 하는 메모리 (프로그램을 통해 직접 읽거나 쓸 수 없음) 

주기억장치 

디스크 캐시 : 주기억장치와 디스크의 속도 차이를 줄이기 위하여 버퍼 역할 /  디스크 쓰기 동작을 
묶음별로 처리 가능하게 함

디스크  

자기테이프 및 CD-ROM

하위 계층으로 내려갈수록 용량이 더 커지고 비트당 가격은 떨어지는 반면에, 지역성의 원리로 인하여 액세스 빈도가
더 낮아진다.

# 반도체 기억장치

현재 주기억장치 소자로 반도체 기억장치 칩들이 사용됨

RAM(Random Access Memory) : 임의 액세스 방식을 이용하는 반도체 기억장치
* 읽고 쓰기가 모두 가능
* 휘발성 -> 전원 공급 중단 시 데이터 소멸
* 분류
    * DRAM : 충전 방식을 이용하여 데이터를 저장하는 RAM / 주기적인 재충전 필요
        * SRAM에 비해 밀도가 높고 더욱 저렴
        * 주로 주기억장치로 사용
    * SRAM : 전력이 공급되는 동안 데이터가 계속 유지되는 RAM
        * DRAM에 비해 속도가 더 빠름
        * 높은 속도가 필요한 캐시로 사용
ROM(Read Only Memory) : 내용을 읽는 것만 가능하고, 쓰는 것은 불가능
* 프로그램이나 변경될 수 없는 데이터를 저장하는 데 사용
    * 시스템 초기화 및 진단 프로그램
    * 빈번히 사용되는 함수들과 서브루틴
    * 제어 유니트의 마이크로 프로그램
* 데이터가 영구 저장되므로 보조저장장치로부터 매번 이동시킬 필요 없기 때문에 액세스 시간이 짧아짐
* 종류
    * PROM(Programmable ROM) : 구입하고 한 번 원하는 내용을 쓸 수 있음
    * EPROM(Erasalbe Programmable ROM) : 내용을 여러 번 갱신 가능
    * EEPROM(Electrically Erasable PROM) : 새로운 내용으로 갱신하기 위해 이전 내용 지울 필요 없음
      비휘발성이면서도 읽기와 쓰기가 모두 가능
    * 플래시 메모리 : 갱신 가능 / 전체 칩 내용을 지우는데 걸리는 시간이 수 초정도로 짧음

# 기억장치 모듈의 설계

# 캐시 메모리

캐시 메모리 : CPU와 주기억장치의 속도 차이를 보완하기 위하여 그 사이에 설치하는 반도체 기억장치
* CPU와 주기억장치의 속도 차이로 인한 성능 저하를 방지하기 위한 방법
* CPU가 기억장치로부터 데이터 읽을 때 캐시부터 먼저 검사 -> 있으면 바로 인출해서 시간 단축
* 주기억장치로부터 한 번 인출되면 그 데이터는 캐시에도 적재 -> 재사용시 신속히 사용 가능
* CPU가 원하는 데이터 있으면 캐시 적중(cache hit) / 없으면 캐시 미스(cache miss)
* 캐시 적중률(cache hit ratio)
    * 캐시가 적중되는 횟수 / 전체 기억장치 액세스 횟수
    * 캐시 적중률 역시 프로그램과 데이터의 지역성에 크게 의존
        * 시간적 지역성 : 최근 액세스된 프로그램과 데이터, 가까운 미래에 
        다시 액세스될 가능성 높아지는 특성 ex) 반복 루프, 서브루틴
        * 공간적 지역성 : 서로 인접하여 저장된 데이터들이 연속적으로 액세스될
        가능성이 높아지는 특성 ex) 배열 데이터
        * 순차적 지역성 : 분기가 발생하지 않는 한 명령어들은 기억장치에 저장된
        순서대로 인출되어 실행
* 캐시 성능에 영향을 미치는 요인
    * 캐시 용량 : 캐시 용량이 커질수록 적중률 높아짐 / 동시에 비용도 상승
    * 인출 방식 : CPU가 원하는 정보를 인출할 때 그 정보와 근접한 위치에 있는 정보들을 함께 인출하여 캐시에 적재
    => 그 이유는 인접한 것들이 지역성에 의해 연속적으로 액세스될 가능성이 많아서 캐시 적중률이 높아질 수 있기 때문
    대신 그만큼 읽어들이는 시간이 길어지는데 지역성이 높으면 효율적이지만 그렇지 않다면 오히려 비효율적
       * 블록 : 주기억장치를 액세스할 때 함께 인출되는 정보들의 그룹
       * 캐시는 m개의 라인(슬롯)들로 구성 / 캐시의 용량이 작기 때문에 캐시 라인의 수는 주기억장치 블록의 수보다 훨씬
         더 적다. -> 일부분만 캐시에 저장될 수 있음 
       * 캐시는 주기억장치보다 용량이 훨씬 더 작기 때문에 캐시의 각 라인은 여러 개의 주기억장치 블록들에 의해 공유
    * 사상 방식 : 어떤 주기억장치 블록들이 어느 캐시 라인을 공유할 것인가? 이를 '사상 방식'이라 함
      * 직접 사상 : 주기억장치의 블록들이 특정 라인에만 적재될 수 있는 방식 
           * 상위 태그 필드와 라인 필드를 통해 캐시 제어기가 적재 가능한 라인을 지정해준다.
           그리고 태그 비트 값을 비교하여 캐시 적중 여부를 파악
           * 간단하고 구현하는 비용이 적게 들지만 같은 라인에 사상되는 두 개의 블록들로부터 데이터들을 번갈아 읽어와야
           한다면 그 블록들은 캐시에서 반복적으로 교체될 것이고, 적중률이 낮아진다. 
      * 완전-연관 사상 : 주기억장치의 블록이 캐시의 어떤 라인으로든 적재 가능하도록 허용 
           * 태그값으로 적중 여부를 검사하므로 캐시의 모든 라인들의 태그들과 주기억장치 주소의 태그 필드 내용을 비교하여
            일치하는 것이 있는지 확인해야 함 -> 일치하는 것이 있으면 단어필드에 해당하는 단어를 CPU로 전송 / 없으면 미스
           * 순차 비교하면 시간이 오래 걸리므로 연관 기억장치 활용하는 것이 적절함
           * 캐시에 라인이 비어 있으면 비어있는대로 차례대로 / 다 채워져있으면 교체 알고리즘에 따라 교체
           * 라인의 선택이 자유롭기 때문에 지역성이 높은 경우 적중률 높아질 것 
      * 세트-연관 사상 : 직접 사상 방식과 완전-연관 사상 방식의 장점만 취하기 위한 절충안
      라인을 세트로 나누고 직접 사상처럼 모듈러 연산 등을 통해 자리를 찾아가지만 한 세트는 여러 라인으로 구성되어 있기
      때문에 교체되지 않고 다른 라인을 찾아들어갈 수 있도록 하는 방식
    * 교체 알고리즘 : 캐시의 라인들이 블록으로 다 채워졌다면 교체할 수 밖에 없는데 이 때 사용하는 알고리즘
        * LRU(Least Recently Used : LRU) 알고리즘 : 사용되지 않은 채로 가장 오랫동안 적재되어 있던 블록을 교체하는 것
        * FIFO(First-In-First-Out) 알고리즘 : 캐시에 적재된 지 가장 오래된 블록을 교체하는  것
        * LFU(Least Frequently Used) 알고리즘 : 캐시에 적재된 이후 참조된 횟수가 가장 적은 블록 교체
    * 쓰기 정책 : 
    * 다중 캐시 : 최근 캐시들이 계층적 구조로 설치되거나 기능별로 분리된 다수의 캐시들을 사용하는 것이 보편화되고 있음
        * 온 칩 캐시와 계층적 캐시
            * 온 칩 캐시 : 원래 캐시는 별도의 SRAM 칩을 사용하여 CPU와 가까운 곳에 위치시켰음. 그러나 칩에 집적할 수 있는
            회로의 밀도가 높아지면서 캐시를 CPU 칩 내부에 포함시키는 것이 가능해짐 -> 그것이 '온 칩 캐시'
            액세스 속도가 높아져 전체 시스템의 성능을 향상시킨다.
            * 계층적 캐시 : 온 칩 캐시를 제 1의 캐시로 두고 별도의 캐시를 외부에 하나 더 두는 것이다. 온 칩 캐시의 용량은 
            적을 수 밖에 없기 때문에 먼저 온 칩 캐시를 검사하고 없으면 외부 캐시를 검사함으로써 서로 보완할 수 있도록 하는 
            것이다.
        * 분리 캐시
            * 온 칩 캐시가 도입되었을 때 대부분의 프로세서는 데이터와 명령어를 모두 하나의 캐시에 저장했는데 최근에는 
            명령어만을 저장하는 명령어 캐시와 데이터만을 저장하는 데이터 캐시로 분리시켜 사용하고 있음
            * 이를 통해 명령어 인출 단계와 오퍼랜드 인출 단계 간에 캐시에 대한 충돌 현상을 제거할 수 있다.





